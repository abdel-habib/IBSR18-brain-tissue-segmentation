{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b225fc-c808-4ba4-80c2-de1cea6f6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import json\n",
    "from EM import NiftiManager, Evaluate, EM, ElastixTransformix, FileManager\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5e06c0-a603-4a8c-94c0-5f97b202f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "NM    = NiftiManager()\n",
    "EVAL  = Evaluate()\n",
    "ET    = ElastixTransformix()\n",
    "FM    = FileManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d26c5b2-e009-47e0-82c8-0ad683217510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastix version: 4.700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ET.excute_cmd('elastix --version'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633bce8-9189-4456-b65a-480defad08a3",
   "metadata": {},
   "source": [
    "Loading the Registration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b967479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Par0010affine.txt', 'Par0010bspline.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./registration-parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98531b07-ccfe-4fb2-b227-3a8624f34b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_params = '-p \"./registration-parameters/Par0010affine.txt\" -p \"./registration-parameters/Par0010bspline.txt\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da567ff7-0e14-4515-9eaa-18e72f18fbc4",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4db9c1-50a0-475c-8d5e-13ac4a13a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../TrainingValidationTestSets/Training_Set'\n",
    "valid_path = '../TrainingValidationTestSets/Validation_Set'\n",
    "test_path  = '../TrainingValidationTestSets/Test_Set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b93c11-84bb-4de5-b12d-00081e6df1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_volumes = sorted(glob(os.path.join(train_path, \"***\", \"IBSR_*.nii.gz\"), recursive=True))\n",
    "train_volumes = [path for path in train_volumes if 'seg' not in path]\n",
    "\n",
    "train_labels  = sorted(glob(os.path.join(train_path, \"***\", \"IBSR_*_seg.nii.gz\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4899941-eb9e-4ba6-a00a-419989cb9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_volumes = sorted(glob(os.path.join(valid_path, \"***\", \"IBSR_*.nii.gz\"), recursive=True))\n",
    "valid_volumes = [path for path in valid_volumes if 'seg' not in path]\n",
    "\n",
    "valid_labels  = sorted(glob(os.path.join(valid_path, \"***\", \"IBSR_*_seg.nii.gz\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d77af20-848c-48e6-b003-0237b70cc091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../TrainingValidationTestSets/Validation_Set\\\\IBSR_11\\\\IBSR_11.nii.gz',\n",
       " '../TrainingValidationTestSets/Validation_Set\\\\IBSR_12\\\\IBSR_12.nii.gz',\n",
       " '../TrainingValidationTestSets/Validation_Set\\\\IBSR_13\\\\IBSR_13.nii.gz',\n",
       " '../TrainingValidationTestSets/Validation_Set\\\\IBSR_14\\\\IBSR_14.nii.gz',\n",
       " '../TrainingValidationTestSets/Validation_Set\\\\IBSR_17\\\\IBSR_17.nii.gz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4328aa50-1556-4416-b589-e467e1e10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_volumes = sorted(glob(os.path.join(test_path, \"***\", \"IBSR_*.nii.gz\"), recursive=True))\n",
    "test_volumes = [path for path in test_volumes if 'seg' not in path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3e3b8-d18c-4fdd-a248-83250f7d4ede",
   "metadata": {},
   "source": [
    "Registration and label propagation (all training to all targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d1ff03b-b416-4bed-a3c1-b89908031b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fixed IBSR_11 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [24:29, 146.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fixed IBSR_12 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [24:24, 146.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fixed IBSR_13 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [41:36, 249.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fixed IBSR_14 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [24:21, 146.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fixed IBSR_17 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [24:59, 149.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# we will assume the valid set is the test to be able to evaluate our approach for now\n",
    "\n",
    "for fixed_volume, fixed_label in zip(valid_volumes, valid_labels): \n",
    "    image_id = fixed_volume.replace('\\\\', '/').split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    print(f\"------------- Fixed {image_id} -------------\")\n",
    "    \n",
    "    for train_volume, train_label in tqdm(zip(train_volumes, train_labels)):\n",
    "        reg_moving_name = train_volume.replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        # register an example train volume to the test space\n",
    "        ET.register_elastix(\n",
    "            fixed_path = fixed_volume, \n",
    "            moving_path = train_volume,\n",
    "            reg_params = reg_params,\n",
    "            create_dir_callback = FM.create_directory_if_not_exists,\n",
    "            excute_cmd_callback = ET.excute_cmd)\n",
    "    \n",
    "        # perform label propagation to test space\n",
    "        ET.label_propagation_transformix(\n",
    "            fixed_path = fixed_volume, \n",
    "            moving_path = train_label, \n",
    "            input_label = train_label,\n",
    "            transform_path = f'output/images/output_{image_id}/{reg_moving_name}/TransformParameters.1.txt',\n",
    "            replace_text_in_file_callback = FM.replace_text_in_file,\n",
    "            create_dir_callback = FM.create_directory_if_not_exists,\n",
    "            excute_cmd_callback = ET.excute_cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9208d2-4718-4cad-8c1b-a13053f2eb02",
   "metadata": {},
   "source": [
    "Note: output folder has been renamed to output_base for the previous experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fde57b-6aac-492e-a93c-f0c112980072",
   "metadata": {},
   "source": [
    "As we observed different voxel sizes accross the dataset, we defined a dataset structure for handling the registration paths, where we will register similar modalities with similar voxel sizes togather to avoid sampling. In `TrainingValidationTestSets\\description.json`, we clustered each given volume to a group and each group will be registered togather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c377fa-5112-44e8-a42f-9229b73265f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing data cluster with voxel sizes (0.9375, 1.5, 0.9375, 0.0). ---\n",
      ">> Processing fixed IBSR_13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:27<00:00, 41.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing fixed IBSR_14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:28<00:00, 41.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing data cluster with voxel sizes (1.0, 1.5, 1.0, 0.0). ---\n",
      ">> Processing fixed IBSR_11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:04<00:00, 41.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing fixed IBSR_12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:02<00:00, 40.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing data cluster with voxel sizes (0.8370536, 1.5, 0.8370536, 0.0). ---\n",
      ">> Processing fixed IBSR_17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:21<00:00, 40.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../TrainingValidationTestSets/description.json', 'r') as json_file:\n",
    "        dataset = json.loads(json_file.read())\n",
    "# FM.pprint_objects(dataset)\n",
    "\n",
    "for modality in dataset:\n",
    "    print(f\"--- Processing data cluster with voxel sizes {modality}. ---\")\n",
    "    # we get the data of the same modality\n",
    "    data_cluster = dataset[modality]\n",
    "\n",
    "    # defining base paths\n",
    "    train_base = '../TrainingValidationTestSets/Training_Set'\n",
    "    valid_base = '../TrainingValidationTestSets/Validation_Set'\n",
    "    test_base  = '../TrainingValidationTestSets/Test_Set'\n",
    "    \n",
    "    # register the data of the same modality to the target\n",
    "    train_group  = data_cluster['train']  # to be modified for inference\n",
    "    target_group = data_cluster['valid']  # to be modified for inference\n",
    "    target_base  = valid_base             # to be modified for inference\n",
    "\n",
    "    for fixed in target_group:\n",
    "        print(f\">> Processing fixed {fixed}...\")\n",
    "        fixed_volume = os.path.join(target_base, fixed, fixed + \".nii.gz\")\n",
    "        fixed_label  = os.path.join(target_base, fixed, fixed + \"_seg.nii.gz\")\n",
    "        # print(fixed_volume, fixed_label)\n",
    "        \n",
    "        for train in tqdm(train_group):\n",
    "            # to be modified for inference: if we merge train and val, train_base has to be altered with a condition to point to both directories\n",
    "            train_volume = os.path.join(train_base, train, train + \".nii.gz\") \n",
    "            train_label  = os.path.join(train_base, train, train + \"_seg.nii.gz\") \n",
    "\n",
    "            # register an example train volume to the test space\n",
    "            ET.register_elastix(\n",
    "                fixed_path = fixed_volume, \n",
    "                moving_path = train_volume,\n",
    "                reg_params = reg_params,\n",
    "                create_dir_callback = FM.create_directory_if_not_exists,\n",
    "                excute_cmd_callback = ET.excute_cmd)\n",
    "\n",
    "            # perform label propagation to test space\n",
    "            ET.label_propagation_transformix(\n",
    "                fixed_path = fixed_volume, \n",
    "                moving_path = train_label, \n",
    "                input_label = train_label,\n",
    "                transform_path = f'output/images/output_{fixed}/{train}/TransformParameters.1.txt',\n",
    "                replace_text_in_file_callback = FM.replace_text_in_file,\n",
    "                create_dir_callback = FM.create_directory_if_not_exists,\n",
    "                excute_cmd_callback = ET.excute_cmd)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
