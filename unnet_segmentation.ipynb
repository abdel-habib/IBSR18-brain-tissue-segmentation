{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/MIC-DKFZ/nnUNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd nnUNet; git checkout nnunetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd nnUNet; pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 14 08:56:15 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti     Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8              N/A / ERR! |      8MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2281      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      2533      G   ...libexec/gnome-remote-desktop-daemon        1MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Python, Pytorch, Cuda info____\n",
      "__Python VERSION: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "__pyTorch VERSION: 2.1.1+cu121\n",
      "__CUDA RUNTIME API VERSION\n",
      "__CUDNN VERSION: 8902\n",
      "_____nvidia-smi GPU details____\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA GeForce GTX 1050 Ti, 535.129.03, 4096 MiB, 8 MiB, 4032 MiB\n",
      "_____Device assignments____\n",
      "Number CUDA Devices: 1\n",
      "Current cuda device:  0  **May not correspond to nvidia-smi ID above, check visibility parameter\n",
      "Device name:  NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from subprocess import call\n",
    "print('_____Python, Pytorch, Cuda info____')\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA RUNTIME API VERSION')\n",
    "#os.system('nvcc --version')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('_____nvidia-smi GPU details____')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('_____Device assignments____')\n",
    "print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "print ('Current cuda device: ', torch.cuda.current_device(), ' **May not correspond to nvidia-smi ID above, check visibility parameter')\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnUNet_raw should exists since it is on the github\n",
    "### Create Manually the other two folders the results and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "nnUNet_raw = os.path.join(base_dir,'nnUNet_raw')\n",
    "nnUNet_preprocessed = os.path.join(base_dir,'nnUNet_preprocessed')\n",
    "results_folder = os.path.join(base_dir,'nnUNet_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_raw\n"
     ]
    }
   ],
   "source": [
    "print(nnUNet_raw) #Check the directory address is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"nnUNet_raw_data_base\"] = str(nnUNet_raw)\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(nnUNet_preprocessed)\n",
    "os.environ[\"RESULTS_FOLDER\"] = str(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data and preparing for the trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Verifying training set\n",
      "checking case IBSR_01\n",
      "checking case IBSR_02\n",
      "checking case IBSR_03\n",
      "checking case IBSR_04\n",
      "checking case IBSR_05\n",
      "checking case IBSR_06\n",
      "checking case IBSR_07\n",
      "checking case IBSR_08\n",
      "checking case IBSR_09\n",
      "checking case IBSR_10\n",
      "checking case IBSR_11\n",
      "checking case IBSR_12\n",
      "checking case IBSR_13\n",
      "checking case IBSR_14\n",
      "checking case IBSR_15\n",
      "Verifying label values\n",
      "Expected label values are [0, 1, 2, 3]\n",
      "Labels OK\n",
      "Verifying test set\n",
      "Dataset OK\n",
      "IBSR_01\n",
      "IBSR_02\n",
      "IBSR_03\n",
      "IBSR_04\n",
      "IBSR_05\n",
      "IBSR_06\n",
      "IBSR_09\n",
      "IBSR_07\n",
      "IBSR_10\n",
      "IBSR_11\n",
      "IBSR_08\n",
      "IBSR_12\n",
      "IBSR_13\n",
      "IBSR_14\n",
      "IBSR_15\n",
      "\n",
      "\n",
      "\n",
      " Task975_BrainSegmentation\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [138.66666667 115.         147.2       ]\n",
      "the max shape in the dataset is  [154.46429043 121.         153.6       ]\n",
      "the min shape in the dataset is  [131. 109. 136.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [115.         138.66666667 147.2       ]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([112, 128, 160]), 'median_patient_size_in_voxels': array([115, 139, 147]), 'current_spacing': array([1.5   , 0.9375, 0.9375]), 'original_spacing': array([1.5   , 0.9375, 0.9375]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [1, 0, 2]\n",
      "transpose backward [1, 0, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_raw/nnUNet_cropped_data/Task975_BrainSegmentation\n",
      "output_folder: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before:no resampling necessary \n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 111, 131, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 131, 143)} \n",
      "\n",
      "{'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 115, 137, 140)} \n",
      "after:  {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 111, 131, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 137, 140)} \n",
      "\n",
      "{'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 131, 143)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 119, 142, 136)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 119, 142, 136)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: no separate z, order 3\n",
      "{'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 116, 134, 151)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 116, 134, 151)} \n",
      "\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "1 10000\n",
      "1 6753\n",
      "1 10000\n",
      "1 6662\n",
      "1 8023\n",
      "2 10000\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_01.npz\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_04.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_05.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_02.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_03.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 115, 136, 149)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 136, 149)} \n",
      "\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_13.npz\n",
      "no separate z, order 1\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 116, 144, 146)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 116, 144, 146)} \n",
      "\n",
      "1 10000\n",
      "no separate z, order 1\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_14.npz\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 115, 138, 138)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 147, 147)} \n",
      "\n",
      "no separate z, order 3\n",
      "1 10000\n",
      "2 10000\n",
      "no separate z, order 1\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_08.npz\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 113, 128, 132)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 113, 137, 141)} \n",
      "\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_06.npz\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 109, 130, 144)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 109, 139, 154)} \n",
      "\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 109, 130, 135)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 109, 139, 144)} \n",
      "\n",
      "1 10000\n",
      "1 10000\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_11.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_07.npz\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 115, 159, 167)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 142, 149)} \n",
      "\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 111, 133, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 142, 153)} \n",
      "\n",
      "1 9419\n",
      "1 10000\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_12.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_09.npz\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 121, 173, 166)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 121, 154, 148)} \n",
      "\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_10.npz\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 120, 165, 171)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 120, 147, 153)} \n",
      "\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_stage0/IBSR_15.npz\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [138.66666667 115.         147.2       ]\n",
      "the max shape in the dataset is  [154.46429043 121.         153.6       ]\n",
      "the min shape in the dataset is  [131. 109. 136.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [115.         138.66666667 147.2       ]\n",
      "[{'batch_size': 69, 'num_pool_per_axis': [5, 5], 'patch_size': array([160, 160]), 'median_patient_size_in_voxels': array([115, 139, 147]), 'current_spacing': array([1.5   , 0.9375, 0.9375]), 'original_spacing': array([1.5   , 0.9375, 0.9375]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_raw/nnUNet_cropped_data/Task975_BrainSegmentation\n",
      "output_folder: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 111, 131, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 131, 143)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 115, 137, 140)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 137, 140)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 111, 131, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 131, 143)} \n",
      "\n",
      "no separate z, order 3\n",
      "normalization...\n",
      "no separate z, order 3\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 119, 142, 136)} \n",
      "after:  no resampling necessary{'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 119, 142, 136)}\n",
      " \n",
      "\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 116, 134, 151)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 116, 134, 151)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "no separate z, order 3\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "normalization done\n",
      "1 6662\n",
      "normalization done\n",
      "normalization done\n",
      "1 6753\n",
      "1 10000\n",
      "1 8023\n",
      "2 10000\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_02.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_04.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_01.npz\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_05.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_03.npz\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no separate z, order 3\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 115, 136, 149)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 136, 149)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_13.npz\n",
      "no separate z, order 1\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.9375, 1.5   , 0.9375]), 'spacing_transposed': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is transposed)': (1, 116, 144, 146)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 116, 144, 146)} \n",
      "\n",
      "no separate z, order 1\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "no separate z, order 1\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_14.npz\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 1\n",
      "no separate z, order 3\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 113, 128, 132)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 113, 137, 141)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 109, 130, 135)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 109, 139, 144)} \n",
      "\n",
      "normalization...\n",
      "1 10000\n",
      "no separate z, order 1\n",
      "normalization done\n",
      "1 10000\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 115, 138, 138)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 147, 147)} \n",
      "\n",
      "normalization...\n",
      "2 10000\n",
      "normalization done\n",
      "2 10000\n",
      "1 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_06.npz\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_07.npz\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_08.npz\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 115, 159, 167)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 115, 142, 149)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 9419\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_09.npz\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 109, 130, 144)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 109, 139, 154)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "2 10000\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 121, 173, 166)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 121, 154, 148)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_11.npz\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_10.npz\n",
      "before: {'spacing': array([1. , 1.5, 1. ]), 'spacing_transposed': array([1.5, 1. , 1. ]), 'data.shape (data is transposed)': (1, 111, 133, 143)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 111, 142, 153)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_12.npz\n",
      "no separate z, order 1\n",
      "before: {'spacing': array([0.8370536, 1.5      , 0.8370536]), 'spacing_transposed': array([1.5      , 0.8370536, 0.8370536]), 'data.shape (data is transposed)': (1, 120, 165, 171)} \n",
      "after:  {'spacing': array([1.5   , 0.9375, 0.9375]), 'data.shape (data is resampled)': (1, 120, 147, 153)} \n",
      "\n",
      "normalization...\n",
      "normalization done\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "saving:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D_stage0/IBSR_15.npz\n"
     ]
    }
   ],
   "source": [
    "! nnUNet_plan_and_preprocess -t 975 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- To train - nnUNet_train TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD\n",
    "- To resume - nnUNet_train TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD -c (just add -c to the training command)\n",
    "- TRAINER_CLASS_NAME - 2d, 3d_fullres, 3d_lowres, 3d_cascade_fullres\n",
    "- Everything will be stored in the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNet_train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  3\n",
      "modalities:  {0: 'T1'}\n",
      "use_mask_for_norm OrderedDict([(0, True)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 69, 'num_pool_per_axis': [5, 5], 'patch_size': array([160, 160]), 'median_patient_size_in_voxels': array([115, 139, 147]), 'current_spacing': array([1.5   , 0.9375, 0.9375]), 'original_spacing': array([1.5   , 0.9375, 0.9375]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2023-12-14 08:57:12.227470: Using splits from existing split file: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Task975_BrainSegmentation/splits_final.pkl\n",
      "2023-12-14 08:57:12.227825: The split file contains 5 splits.\n",
      "2023-12-14 08:57:12.227889: Desired fold for training: 3\n",
      "2023-12-14 08:57:12.227946: This split has 12 training and 3 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-12-14 08:57:12.996336: lr: 0.01\n",
      "2023-12-14 08:57:13.018128: WARNING!!! You are attempting to run training on a CPU (torch.cuda.is_available() is False). This can be VERY slow!\n",
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1513: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-12-14 08:57:24.614828: Unable to plot network architecture:\n",
      "2023-12-14 08:57:24.614965: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-12-14 08:57:24.615028: \n",
      "printing the network instead:\n",
      "\n",
      "2023-12-14 08:57:24.615082: Generic_UNet(\n",
      "  (conv_blocks_localization): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(960, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_blocks_context): ModuleList(\n",
      "    (0): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): StackedConvLayers(\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(256, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): StackedConvLayers(\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvDropoutNormNonlin(\n",
      "            (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (instnorm): InstanceNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (td): ModuleList()\n",
      "  (tu): ModuleList(\n",
      "    (0): ConvTranspose2d(480, 480, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (1): ConvTranspose2d(480, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (seg_outputs): ModuleList(\n",
      "    (0): Conv2d(480, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (3): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (4): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2023-12-14 08:57:24.618245: \n",
      "\n",
      "2023-12-14 08:57:24.618509: \n",
      "epoch:  0\n",
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! nnUNet_train 2d nnUNetTrainerV2 Task975_BrainSegmentation 3 --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "running missing postprocessing for Task975_BrainSegmentation and model 2d\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/bin/nnUNet_find_best_configuration\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_find_best_configuration')())\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunet/evaluation/model_selection/figure_out_what_to_submit.py\", line 144, in main\n",
      "    consolidate_folds(output_folder, folds=folds)\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunet/postprocessing/consolidate_postprocessing.py\", line 61, in consolidate_folds\n",
      "    collect_cv_niftis(output_folder_base, output_folder_raw, validation_folder_name,\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunet/postprocessing/consolidate_postprocessing.py\", line 38, in collect_cv_niftis\n",
      "    niftis = subfiles(validation_raw_folders[f], suffix=\".nii.gz\")\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "! nnUNet_find_best_configuration -m 2d -t 975 -f 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_predict -d Dataset975_BrainSegmentation -i nnUNet_raw/Dataset975_BrainSegmentation/imagesTr -o outTrainning/ -f  3 -tr nnUNetTrainer_5epochs -c 2d -p nnUNetPlans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_apply_postprocessing -i outTrainning/ -o outTrainning/outTrainningpp/ -pp_pkl_file /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/postprocessing.pkl -np 8 -plans_json /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/plans.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_predict -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_predict -d Dataset975_BrainSegmentation -i nnUNet_raw/Dataset975_BrainSegmentation/imagesTs -o outTest/ -f  3 -tr nnUNetTrainer_5epochs -c 2d -p nnUNetPlans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectMisaMira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
