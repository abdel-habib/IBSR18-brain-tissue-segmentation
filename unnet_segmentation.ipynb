{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/MIC-DKFZ/nnUNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  6 16:32:10 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti     Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8              N/A / ERR! |      6MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2291      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      2573      G   ...libexec/gnome-remote-desktop-daemon        1MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnUNet_raw should exists since it is on the github\n",
    "### Create Manually the other two folders the results and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "nnUNet_raw = os.path.join(base_dir,'nnUNet_raw')\n",
    "nnUNet_preprocessed = os.path.join(base_dir,'nnUNet_preprocessed')\n",
    "results_folder = os.path.join(base_dir,'nnUNet_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_raw\n"
     ]
    }
   ],
   "source": [
    "print(nnUNet_raw) #Check the directory address is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"nnUNet_raw\"] = str(nnUNet_raw)\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(nnUNet_preprocessed)\n",
    "os.environ[\"nnUNet_results\"] = str(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data and preparing for the trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset975_BrainSegmentation\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Experiment planning...\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': array([160, 160]), 'median_image_size_in_voxels': array([139., 147.]), 'spacing': array([0.9375, 0.9375]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': array([112, 128, 160]), 'median_image_size_in_voxels': array([115., 139., 147.]), 'spacing': array([1.5   , 0.9375, 0.9375]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'num_pool_per_axis': [4, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Dataset975_BrainSegmentation/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset975_BrainSegmentation\n",
      "Configuration: 2d...\n",
      "100%|███████████████████████████████████████████| 15/15 [00:15<00:00,  1.04s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|███████████████████████████████████████████| 15/15 [00:15<00:00,  1.06s/it]\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset975_BrainSegmentation. Skipping.\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_plan_and_preprocess -d 975 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- To train - nnUNet_train TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD\n",
    "- To resume - nnUNet_train TRAINER_CLASS_NAME TASK_NAME_OR_ID FOLD -c (just add -c to the training command)\n",
    "- TRAINER_CLASS_NAME - 2d, 3d_fullres, 3d_lowres, 3d_cascade_fullres\n",
    "- Everything will be stored in the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
      "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
      "                      [-num_gpus NUM_GPUS] [--use_compressed] [--npz] [--c]\n",
      "                      [--val] [--val_best] [--disable_checkpointing]\n",
      "                      [-device DEVICE]\n",
      "                      dataset_name_or_id configuration fold\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset name or ID to train with\n",
      "  configuration         Configuration that should be trained\n",
      "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
      "                        between 0 and 4.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
      "                        Default: nnUNetTrainer\n",
      "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
      "                        identifier. Default: nnUNetPlans\n",
      "  -pretrained_weights PRETRAINED_WEIGHTS\n",
      "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
      "                        as pretrained model. Will only be used when actually\n",
      "                        training. Beta. Use with caution.\n",
      "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
      "  --use_compressed      [OPTIONAL] If you set this flag the training cases\n",
      "                        will not be decompressed. Reading compressed data is\n",
      "                        much more CPU and (potentially) RAM intensive and\n",
      "                        should only be used if you know what you are doing\n",
      "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
      "                        validation as npz files (in addition to predicted\n",
      "                        segmentations). Needed for finding the best ensemble.\n",
      "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
      "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
      "                        Requires training to have finished.\n",
      "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
      "                        with the checkpoint_best instead of checkpoint_final.\n",
      "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
      "                        This will use the same 'validation' folder as the\n",
      "                        regular validation with no way of distinguishing the\n",
      "                        two!\n",
      "  --disable_checkpointing\n",
      "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
      "                        Ideal for testing things out and you dont want to\n",
      "                        flood your hard drive with checkpoints.\n",
      "  -device DEVICE        Use this to set the device the training should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset975_BrainSegmentation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 136, 143], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 89.31542205810547, 'median': 67.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 100.35749816894531}}} \n",
      "\n",
      "2023-12-06 16:36:45.827266: unpacking dataset...\n",
      "2023-12-06 16:36:52.496098: unpacking done...\n",
      "2023-12-06 16:36:52.497773: do_dummy_2d_data_aug: False\n",
      "2023-12-06 16:36:52.498818: Using splits from existing split file: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Dataset975_BrainSegmentation/splits_final.json\n",
      "2023-12-06 16:36:52.499637: The split file contains 5 splits.\n",
      "2023-12-06 16:36:52.499799: Desired fold for training: 3\n",
      "2023-12-06 16:36:52.499927: This split has 12 training and 3 validation cases.\n",
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/lib/python3.10/site-packages/torch/onnx/symbolic_helper.py:1513: UserWarning: ONNX export mode is set to TrainingMode.EVAL, but operator 'instance_norm' is set to train=True. Exporting with train=True.\n",
      "  warnings.warn(\n",
      "2023-12-06 16:36:57.180803: Unable to plot network architecture:\n",
      "2023-12-06 16:36:57.181214: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "2023-12-06 16:36:58.099994: Training done.\n",
      "2023-12-06 16:36:58.132573: Using splits from existing split file: /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_preprocessed/Dataset975_BrainSegmentation/splits_final.json\n",
      "2023-12-06 16:36:58.133590: The split file contains 5 splits.\n",
      "2023-12-06 16:36:58.134018: Desired fold for training: 3\n",
      "2023-12-06 16:36:58.134345: This split has 12 training and 3 validation cases.\n",
      "2023-12-06 16:36:58.135118: predicting IBSR_005\n",
      "2023-12-06 16:37:19.643169: predicting IBSR_010\n",
      "2023-12-06 16:37:34.129272: predicting IBSR_014\n",
      "2023-12-06 16:38:00.794837: Validation complete\n",
      "2023-12-06 16:38:00.794979: Mean Validation Dice:  0.9237843734958894\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_train 975 2d 3 -tr nnUNetTrainer_5epochs --npz --c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***All results:***\n",
      "nnUNetTrainer_5epochs__nnUNetPlans__2d: 0.9237843734958894\n",
      "\n",
      "*Best*: nnUNetTrainer_5epochs__nnUNetPlans__2d: 0.9237843734958894\n",
      "\n",
      "***Determining postprocessing for best model/ensemble***\n",
      "WARNING: Not all files in folder_ref were found in folder_predictions. Determining postprocessing should always be done on the entire dataset!\n",
      "Results were improved by removing all but the largest foreground region. Mean dice before: 0.92378 after: 0.92378\n",
      "Removing all but the largest component for 1 did not improve results! Dice before: 0.90996 after: 0.86224\n",
      "Results were improved by removing all but the largest component for 2. Dice before: 0.93355 after: 0.93361\n",
      "Removing all but the largest component for 3 did not improve results! Dice before: 0.92784 after: 0.89648\n",
      "\n",
      "***Run inference like this:***\n",
      "\n",
      "nnUNetv2_predict -d Dataset975_BrainSegmentation -i INPUT_FOLDER -o OUTPUT_FOLDER -f  3 -tr nnUNetTrainer_5epochs -c 2d -p nnUNetPlans\n",
      "\n",
      "***Once inference is completed, run postprocessing like this:***\n",
      "\n",
      "nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/postprocessing.pkl -np 8 -plans_json /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/plans.json\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_find_best_configuration 975 -c 2d -f 3 -tr nnUNetTrainer_5epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 15 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 15 cases that I would like to predict\n",
      "\n",
      "Predicting IBSR_001:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 111/111 [00:07<00:00, 14.86it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_001\n",
      "\n",
      "Predicting IBSR_002:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 111/111 [00:07<00:00, 15.56it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_002\n",
      "\n",
      "Predicting IBSR_003:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 116/116 [00:07<00:00, 15.48it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_003\n",
      "\n",
      "Predicting IBSR_004:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 115/115 [00:07<00:00, 15.45it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_004\n",
      "\n",
      "Predicting IBSR_005:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 119/119 [00:07<00:00, 15.43it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_005\n",
      "\n",
      "Predicting IBSR_006:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 113/113 [00:07<00:00, 15.45it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_006\n",
      "\n",
      "Predicting IBSR_007:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 109/109 [00:07<00:00, 15.41it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_007\n",
      "\n",
      "Predicting IBSR_008:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 115/115 [00:07<00:00, 15.39it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_008\n",
      "\n",
      "Predicting IBSR_009:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 115/115 [00:07<00:00, 15.39it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_009\n",
      "\n",
      "Predicting IBSR_010:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 121/121 [00:07<00:00, 15.38it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_010\n",
      "\n",
      "Predicting IBSR_011:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 109/109 [00:07<00:00, 15.39it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_011\n",
      "\n",
      "Predicting IBSR_012:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 111/111 [00:07<00:00, 15.39it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_012\n",
      "\n",
      "Predicting IBSR_013:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 115/115 [00:07<00:00, 15.36it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_013\n",
      "\n",
      "Predicting IBSR_014:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 116/116 [00:07<00:00, 15.32it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_014\n",
      "\n",
      "Predicting IBSR_015:\n",
      "perform_everything_on_gpu: True\n",
      "100%|█████████████████████████████████████████| 120/120 [00:07<00:00, 15.33it/s]\n",
      "Prediction done, transferring to CPU if needed\n",
      "sending off prediction to background worker for resampling and export\n",
      "done with IBSR_015\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_predict -d Dataset975_BrainSegmentation -i nnUNet_raw/Dataset975_BrainSegmentation/imagesTr -o outTrainning/ -f  3 -tr nnUNetTrainer_5epochs -c 2d -p nnUNetPlans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_apply_postprocessing -i outTrainning/ -o outTrainning/outTrainningpp/ -pp_pkl_file /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/postprocessing.pkl -np 8 -plans_json /home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet_results/Dataset975_BrainSegmentation/nnUNetTrainer_5epochs__nnUNetPlans__2d/crossval_results_folds_3/plans.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation\n"
     ]
    }
   ],
   "source": [
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "usage: nnUNetv2_predict [-h] -i I -o O -d D [-p P] [-tr TR] -c C\n",
      "                        [-f F [F ...]] [-step_size STEP_SIZE] [--disable_tta]\n",
      "                        [--verbose] [--save_probabilities]\n",
      "                        [--continue_prediction] [-chk CHK] [-npp NPP]\n",
      "                        [-nps NPS]\n",
      "                        [-prev_stage_predictions PREV_STAGE_PREDICTIONS]\n",
      "                        [-num_parts NUM_PARTS] [-part_id PART_ID]\n",
      "                        [-device DEVICE]\n",
      "\n",
      "Use this to run inference with nnU-Net. This function is used when you want to\n",
      "manually specify a folder containing a trained nnU-Net model. This is useful\n",
      "when the nnunet environment variables (nnUNet_results) are not set.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i I                  input folder. Remember to use the correct channel\n",
      "                        numberings for your files (_0000 etc). File endings\n",
      "                        must be the same as the training dataset!\n",
      "  -o O                  Output folder. If it does not exist it will be\n",
      "                        created. Predicted segmentations will have the same\n",
      "                        name as their source images.\n",
      "  -d D                  Dataset with which you would like to predict. You can\n",
      "                        specify either dataset name or id\n",
      "  -p P                  Plans identifier. Specify the plans in which the\n",
      "                        desired configuration is located. Default: nnUNetPlans\n",
      "  -tr TR                What nnU-Net trainer class was used for training?\n",
      "                        Default: nnUNetTrainer\n",
      "  -c C                  nnU-Net configuration that should be used for\n",
      "                        prediction. Config must be located in the plans\n",
      "                        specified with -p\n",
      "  -f F [F ...]          Specify the folds of the trained model that should be\n",
      "                        used for prediction. Default: (0, 1, 2, 3, 4)\n",
      "  -step_size STEP_SIZE  Step size for sliding window prediction. The larger it\n",
      "                        is the faster but less accurate the prediction.\n",
      "                        Default: 0.5. Cannot be larger than 1. We recommend\n",
      "                        the default.\n",
      "  --disable_tta         Set this flag to disable test time data augmentation\n",
      "                        in the form of mirroring. Faster, but less accurate\n",
      "                        inference. Not recommended.\n",
      "  --verbose             Set this if you like being talked to. You will have to\n",
      "                        be a good listener/reader.\n",
      "  --save_probabilities  Set this to export predicted class \"probabilities\".\n",
      "                        Required if you want to ensemble multiple\n",
      "                        configurations.\n",
      "  --continue_prediction\n",
      "                        Continue an aborted previous prediction (will not\n",
      "                        overwrite existing files)\n",
      "  -chk CHK              Name of the checkpoint you want to use. Default:\n",
      "                        checkpoint_final.pth\n",
      "  -npp NPP              Number of processes used for preprocessing. More is\n",
      "                        not always better. Beware of out-of-RAM issues.\n",
      "                        Default: 3\n",
      "  -nps NPS              Number of processes used for segmentation export. More\n",
      "                        is not always better. Beware of out-of-RAM issues.\n",
      "                        Default: 3\n",
      "  -prev_stage_predictions PREV_STAGE_PREDICTIONS\n",
      "                        Folder containing the predictions of the previous\n",
      "                        stage. Required for cascaded models.\n",
      "  -num_parts NUM_PARTS  Number of separate nnUNetv2_predict call that you will\n",
      "                        be making. Default: 1 (= this one call predicts\n",
      "                        everything)\n",
      "  -part_id PART_ID      If multiple nnUNetv2_predict exist, which one is this?\n",
      "                        IDs start with 0 can end with num_parts - 1. So when\n",
      "                        you submit 5 nnUNetv2_predict calls you need to set\n",
      "                        -num_parts 5 and use -part_id 0, 1, 2, 3 and 4.\n",
      "                        Simple, right? Note: You are yourself responsible to\n",
      "                        make these run on separate GPUs! Use\n",
      "                        CUDA_VISIBLE_DEVICES (google, yo!)\n",
      "  -device DEVICE        Use this to set the device the inference should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_predict\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_predict -h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 3 cases in the source folder\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/projectMisaMira/bin/nnUNetv2_predict\", line 8, in <module>\n",
      "    sys.exit(predict_entry_point())\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunetv2/inference/predict_from_raw_data.py\", line 838, in predict_entry_point\n",
      "    predictor.predict_from_files(args.i, args.o, save_probabilities=args.save_probabilities,\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunetv2/inference/predict_from_raw_data.py\", line 237, in predict_from_files\n",
      "    self._manage_input_and_output_lists(list_of_lists_or_source_folder,\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunetv2/inference/predict_from_raw_data.py\", line 162, in _manage_input_and_output_lists\n",
      "    caseids = [os.path.basename(i[0])[:-(len(self.dataset_json['file_ending']) + 5)] for i in\n",
      "  File \"/home/edalita/Documents/MAIA/3-Semestre/MIRMISAProject/IBSR18-tissue-segmentation/nnUNet/nnunetv2/inference/predict_from_raw_data.py\", line 162, in <listcomp>\n",
      "    caseids = [os.path.basename(i[0])[:-(len(self.dataset_json['file_ending']) + 5)] for i in\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "! nnUNetv2_predict -d Dataset975_BrainSegmentation -i nnUNet_raw/Dataset975_BrainSegmentation/imagesTs -o outTest/ -f  3 -tr nnUNetTrainer_5epochs -c 2d -p nnUNetPlans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectMisaMira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
